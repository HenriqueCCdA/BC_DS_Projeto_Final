{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f67c67a-a7ac-47c1-b604-c08fb41af8dc",
   "metadata": {},
   "source": [
    "---\n",
    "# 1) Resumo\n",
    "\n",
    "Neste notebook foram feitos os treinamentos com 4 seleções de variaveis diferentes, são elas:\n",
    "\n",
    "* Pela lib featurewiz com 25 variaveis (df_featurewiz_25). [Link para o notebook](https://github.com/HenriqueCCdA/BC_DS_Projeto_Final/blob/main/Notebooks/Selecao_variaveis/selecao_variaveis_featurewiz.ipynb)\n",
    "* Pela matriz de correlação com 41 variaveis (df_corr_41). [Link para o notebook](https://github.com/HenriqueCCdA/BC_DS_Projeto_Final/blob/main/Notebooks/Selecao_variaveis/selecao_variaveis.ipynb).\n",
    "* Pela matriz de correlação + RFE com 30 variaveis (df_RFE_30). [Link para o notebook](https://github.com/HenriqueCCdA/BC_DS_Projeto_Final/blob/main/Notebooks/Selecao_variaveis/selecao_variaveis_sklearn.ipynb)\n",
    "* Pela matriz de correlação + RFE com 20 variaveis (df_RFE_20). [Link para o notebook](https://github.com/HenriqueCCdA/BC_DS_Projeto_Final/blob/main/Notebooks/Selecao_variaveis/selecao_variaveis_sklearn.ipynb)\n",
    "\n",
    "A busca pelos **hyperparametros** foi feita através do **GridSearchCV** ou pelo **RandomizedSearchCV**. Para a **Cross Validation** foi usado **RepeatedStratifiedKFold** com **5** divisões de **10** repetições. O **RandomizedSearchCV** faz uma busca de **20** tentativas no espaço de **hyperparametros**. Por tanto temos 1000 (5x10x20) treinamentos por modelo..\n",
    "\n",
    "O parâmetro utilizado para avaliação do modelo foi **ROC_AUC** e quantidade de **falsos negativos** (FN).\n",
    "\n",
    "Os hyperparamentros seleciona por modelos são os mesmo do [notebook anterior](https://github.com/HenriqueCCdA/BC_DS_Projeto_Final/blob/main/Notebooks/ML/treinamentos_dados1.ipynb). Sendo assim o hyperaramentros são:\n",
    "\n",
    "* DummyClassifier\n",
    "    >* strategy : [stratified, most_frequent, prior, uniform]\n",
    "    \n",
    "* LogisticRegression\n",
    "    >* C : [0, 4]\n",
    "    \n",
    "* DecisionTreeClassifier\n",
    "    >* max_depth       : [1-20]\n",
    "    >* criterion       : [gini, entropy]\n",
    "    >* min_samples_leaf: [1-5]\n",
    "    >* max_leaf_nodes  : [2-5]\n",
    "    \n",
    "* Random Forest Tree\n",
    "    >* n_estimators    : [100, 150, 200, 250, 300, 350, 400]\n",
    "    >* max_depth       : [1, 20]    \n",
    "    >* criterion       : [gini, entropy]\n",
    "    >* min_samples_leaf: [1-5]\n",
    "    >* max_leaf_nodes  : [2-10]\n",
    "    \n",
    "* Support Vector Machine\n",
    "    >* kernel        : [linear, poly, rbf, sigmoid]\n",
    "    >* C             : [0, 2]\n",
    "    >* gamma         : [scale, auto]\n",
    "    >* shrinking     : [True , False]\n",
    "\n",
    "* KNeighbors\n",
    "    >* n_neighbors   : [1, 10]\n",
    "    >* p             : [1, 2]\n",
    "    >* weights       : [uniform, distance]\n",
    "    >* algorithm     : [auto, ball_tree, kd_tree, brute]\n",
    "    \n",
    "Os hyperparametros podem ser encontrado no arquivo python [aqui](https://github.com/HenriqueCCdA/BC_DS_Projeto_Final/blob/main/src/hyperparametros.py).\n",
    "\n",
    "OBS: A base de dados com **41** variaveis é a mesma vista no [notebook anterior (Primeiro Treinamento)](https://github.com/HenriqueCCdA/BC_DS_Projeto_Final/blob/main/Notebooks/ML/treinamentos_dados1.ipynb) anterior, os modelo para essa base serão rodados aqui novamente por questão de praticidade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc087be6-8cf5-48c9-b36c-af347238199f",
   "metadata": {},
   "source": [
    "---\n",
    "# 2) Pre-analise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0db1eaf-ded2-40ee-a101-f85502adb0ea",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.1) Minhas Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01ee6d5-292b-4810-a273-a0871d6cca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../../\")\n",
    "\n",
    "from src.treinamento import treinamentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e17ab3-e7d8-4c59-a86e-8b214c0f6d0c",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.2) Importando libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93fe0a7e-5f9a-4bac-8b8b-e7005f7ccc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaabdccd-b45a-486c-9cee-74aba5a6cc4e",
   "metadata": {},
   "source": [
    "---\n",
    "# 3) Treinando modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e26b1ab2-f4d2-4669-ae6e-ff0f09816348",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter   = 20 # numero de iteração do RandomizedSearchCV\n",
    "n_splits = 5  # Numero de divisões RepeatedStratifiedKFold\n",
    "n_repeats= 10 # NUmero de repitões que RepeatedStratifiedKFold faz a difisão\n",
    "seed     = 1471523"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb124078-931d-4f74-99c2-7a69678c557b",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.1) Seleção pelo featurewiz\n",
    "\n",
    "Feito neste [notebook](https://github.com/HenriqueCCdA/BC_DS_Projeto_Final/blob/10acc58f00f060385488c782c9ae2d2e6d404c08/Notebooks/Selecao_variaveis/selecao_variaveis_featurewiz.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "313db06a-b3bc-4510-9546-c200efeff36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de linhas : 351 \n",
      "Numero de colunas: 26 \n",
      "Número total de entradas                         : 351\n",
      "Número total de entradas para validacao          : 36\n",
      "Número total de entradas para o Cross Validation : 315\n",
      "Treinamento DummyClassifier\n",
      "Fitting 50 folds for each of 4 candidates, totalling 200 fits\n",
      "Treinamento LogisticRegression\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'C': 1.2175467357414327}\n",
      "Melhor modelo            : LogisticRegression(C=1.2175467357414327, max_iter=1000, tol=1e-06)\n",
      "Treinamento DecisionTreeClassifier\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'min_samples_leaf': 4, 'max_leaf_nodes': 5, 'max_depth': 19, 'criterion': 'entropy'}\n",
      "Melhor modelo            : DecisionTreeClassifier(criterion='entropy', max_depth=19, max_leaf_nodes=5,\n",
      "                       min_samples_leaf=4)\n",
      "Treinamento RandomForestClassifier\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'n_estimators': 400, 'min_samples_leaf': 4, 'max_leaf_nodes': 10, 'max_depth': 7, 'criterion': 'entropy'}\n",
      "Melhor modelo            : RandomForestClassifier(criterion='entropy', max_depth=7, max_leaf_nodes=10,\n",
      "                       min_samples_leaf=4, n_estimators=400,\n",
      "                       random_state=RandomState(MT19937) at 0x244DD88D140)\n",
      "Treinamento SVC\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'C': 1.8286516557652102, 'gamma': 'scale', 'kernel': 'rbf', 'shrinking': False}\n",
      "Melhor modelo            : SVC(C=1.8286516557652102, probability=True, shrinking=False)\n",
      "Treinamento KNeighbors\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'weights': 'uniform', 'p': 1, 'n_neighbors': 10, 'algorithm': 'brute'}\n",
      "Melhor modelo            : KNeighborsClassifier(algorithm='brute', n_neighbors=10, p=1)\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/HenriqueCCdA/BC_DS_Projeto_Final/main/Dados/Tratados/dados_featurewiz.csv'\n",
    "#url = '../../Dados/Tratados/dados_featurewiz.csv'\n",
    "df_featurewiz_val, df_featurewiz_cv= treinamentos(path = url, \n",
    "                                     n_iter=n_iter, \n",
    "                                     n_splits=n_splits, \n",
    "                                     n_repeats=n_repeats,\n",
    "                                     seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6493172d-9825-4f0d-a268-aeb3761a46d5",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.2) Seleção pela matriz de correlação \n",
    "\n",
    "Feito neste [notebook](https://github.com/HenriqueCCdA/BC_DS_Projeto_Final/blob/10acc58f00f060385488c782c9ae2d2e6d404c08/Notebooks/Selecao_variaveis/selecao_variaveis.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92c4e91-4a49-4ac7-a03a-8c1d62770baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de linhas : 351 \n",
      "Numero de colunas: 42 \n",
      "Número total de entradas                         : 351\n",
      "Número total de entradas para validacao          : 36\n",
      "Número total de entradas para o Cross Validation : 315\n",
      "Treinamento DummyClassifier\n",
      "Fitting 50 folds for each of 4 candidates, totalling 200 fits\n",
      "Treinamento LogisticRegression\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'C': 1.0804892609644945}\n",
      "Melhor modelo            : LogisticRegression(C=1.0804892609644945, max_iter=1000, tol=1e-06)\n",
      "Treinamento DecisionTreeClassifier\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'max_depth': 8, 'criterion': 'gini'}\n",
      "Melhor modelo            : DecisionTreeClassifier(max_depth=8, max_leaf_nodes=5, min_samples_leaf=5)\n",
      "Treinamento RandomForestClassifier\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'n_estimators': 200, 'min_samples_leaf': 1, 'max_leaf_nodes': 9, 'max_depth': 14, 'criterion': 'gini'}\n",
      "Melhor modelo            : RandomForestClassifier(max_depth=14, max_leaf_nodes=9, n_estimators=200,\n",
      "                       random_state=RandomState(MT19937) at 0x244DD88D340)\n",
      "Treinamento SVC\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'C': 0.8922454592770794, 'gamma': 'scale', 'kernel': 'poly', 'shrinking': True}\n",
      "Melhor modelo            : SVC(C=0.8922454592770794, kernel='poly', probability=True)\n",
      "Treinamento KNeighbors\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'weights': 'uniform', 'p': 2, 'n_neighbors': 10, 'algorithm': 'kd_tree'}\n",
      "Melhor modelo            : KNeighborsClassifier(algorithm='kd_tree', n_neighbors=10)\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/HenriqueCCdA/BC_DS_Projeto_Final/main/Dados/Tratados/dados_sem_corr_acima_do_valor_de_corte.csv'\n",
    "#url = '../../Dados/Tratados/dados_sem_corr_acima_do_valor_de_corte.csv'\n",
    "df_corr_val, df_corr_cv = treinamentos(path=url,\n",
    "                                       n_iter=n_iter, \n",
    "                                       n_splits=n_splits, \n",
    "                                       n_repeats=n_repeats,\n",
    "                                       seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9914c2e2-e4cf-4342-8b6d-c6ea55d1b368",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.3) Seleção pela matriz de correlação e RFE\n",
    "\n",
    "Feito neste [notebook](https://github.com/HenriqueCCdA/BC_DS_Projeto_Final/blob/10acc58f00f060385488c782c9ae2d2e6d404c08/Notebooks/Selecao_variaveis/selecao_variaveis_sklearn.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011815e1-21b2-4c69-bbab-df7206562e9c",
   "metadata": {},
   "source": [
    "* Base com **30** variaveis explicativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a217b5a0-9ab8-42a9-8917-21b54b73e4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de linhas : 351 \n",
      "Numero de colunas: 31 \n",
      "Número total de entradas                         : 351\n",
      "Número total de entradas para validacao          : 36\n",
      "Número total de entradas para o Cross Validation : 315\n",
      "Treinamento DummyClassifier\n",
      "Fitting 50 folds for each of 4 candidates, totalling 200 fits\n",
      "Treinamento LogisticRegression\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'C': 1.1624762277002425}\n",
      "Melhor modelo            : LogisticRegression(C=1.1624762277002425, max_iter=1000, tol=1e-06)\n",
      "Treinamento DecisionTreeClassifier\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'max_depth': 8, 'criterion': 'gini'}\n",
      "Melhor modelo            : DecisionTreeClassifier(max_depth=8, max_leaf_nodes=5, min_samples_leaf=5)\n",
      "Treinamento RandomForestClassifier\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'n_estimators': 250, 'min_samples_leaf': 2, 'max_leaf_nodes': 10, 'max_depth': 18, 'criterion': 'gini'}\n",
      "Melhor modelo            : RandomForestClassifier(max_depth=18, max_leaf_nodes=10, min_samples_leaf=2,\n",
      "                       n_estimators=250,\n",
      "                       random_state=RandomState(MT19937) at 0x244DD88D440)\n",
      "Treinamento SVC\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'C': 0.6981876218629635, 'gamma': 'scale', 'kernel': 'poly', 'shrinking': False}\n",
      "Melhor modelo            : SVC(C=0.6981876218629635, kernel='poly', probability=True, shrinking=False)\n",
      "Treinamento KNeighbors\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'weights': 'uniform', 'p': 1, 'n_neighbors': 10, 'algorithm': 'brute'}\n",
      "Melhor modelo            : KNeighborsClassifier(algorithm='brute', n_neighbors=10, p=1)\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/HenriqueCCdA/BC_DS_Projeto_Final/main/Dados/Tratados/dados_rfe30.csv'\n",
    "#url = '../../Dados/Tratados/dados_rfe30.csv'\n",
    "df_rfe30_val, df_rfe30_cv = treinamentos(path=url,\n",
    "                                          n_iter=n_iter, \n",
    "                                          n_splits=n_splits, \n",
    "                                          n_repeats=n_repeats,\n",
    "                                          seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a45d4f2-8559-40f3-884d-da6cd7474d72",
   "metadata": {},
   "source": [
    "* Base com **20** variaveis explicativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1f9555b-413a-4000-bfa1-97c94ae9584a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de linhas : 351 \n",
      "Numero de colunas: 21 \n",
      "Número total de entradas                         : 351\n",
      "Número total de entradas para validacao          : 36\n",
      "Número total de entradas para o Cross Validation : 315\n",
      "Treinamento DummyClassifier\n",
      "Fitting 50 folds for each of 4 candidates, totalling 200 fits\n",
      "Treinamento LogisticRegression\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'C': 3.074614967936442}\n",
      "Melhor modelo            : LogisticRegression(C=3.074614967936442, max_iter=1000, tol=1e-06)\n",
      "Treinamento DecisionTreeClassifier\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'max_depth': 8, 'criterion': 'gini'}\n",
      "Melhor modelo            : DecisionTreeClassifier(max_depth=8, max_leaf_nodes=5, min_samples_leaf=5)\n",
      "Treinamento RandomForestClassifier\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'n_estimators': 250, 'min_samples_leaf': 2, 'max_leaf_nodes': 10, 'max_depth': 18, 'criterion': 'gini'}\n",
      "Melhor modelo            : RandomForestClassifier(max_depth=18, max_leaf_nodes=10, min_samples_leaf=2,\n",
      "                       n_estimators=250,\n",
      "                       random_state=RandomState(MT19937) at 0x244DD88D740)\n",
      "Treinamento SVC\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'C': 0.8922454592770794, 'gamma': 'scale', 'kernel': 'poly', 'shrinking': True}\n",
      "Melhor modelo            : SVC(C=0.8922454592770794, kernel='poly', probability=True)\n",
      "Treinamento KNeighbors\n",
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n",
      "melhores hyperparametros : {'weights': 'distance', 'p': 2, 'n_neighbors': 10, 'algorithm': 'ball_tree'}\n",
      "Melhor modelo            : KNeighborsClassifier(algorithm='ball_tree', n_neighbors=10, weights='distance')\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/HenriqueCCdA/BC_DS_Projeto_Final/main/Dados/Tratados/dados_rfe20.csv'\n",
    "#url = '../../Dados/Tratados/dados_rfe20.csv'\n",
    "df_rfe20_val, df_rfe20_cv = treinamentos(path='../../Dados/Tratados/dados_rfe20.csv',\n",
    "                                         n_iter=n_iter, \n",
    "                                         n_splits=n_splits, \n",
    "                                         n_repeats=n_repeats,\n",
    "                                         seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7adcda-0450-4e88-8123-5cee4d87838b",
   "metadata": {},
   "source": [
    "# 4) Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5dc7d9-0605-4b2b-868b-6713c23736f8",
   "metadata": {},
   "source": [
    "* Resultado no DataSet de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e818e06f-6589-4341-99b8-35b1f96e3076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Featurewiz_25</th>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.839009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.746130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0.743034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.718266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.577399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Corr_41</th>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0.783282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.733746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.699690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.678019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.577399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RFE_30</th>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0.786378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.741486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.724458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.702786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.577399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RFE_20</th>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0.755418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.708978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.653251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.577399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name  tn  fp  fn  tp       AUC\n",
       "Featurewiz_25 0  RandomForestClassifier  13   6   6  11  0.839009\n",
       "              1    KNeighborsClassifier  16   3   8   9  0.746130\n",
       "              2                     SVC  13   6   5  12  0.743034\n",
       "              3  DecisionTreeClassifier   9  10   2  15  0.736842\n",
       "              4      LogisticRegression  14   5   7  10  0.718266\n",
       "              5         DummyClassifier  10   9   7  10  0.577399\n",
       "Corr_41       0  RandomForestClassifier  12   7   5  12  0.783282\n",
       "              1  DecisionTreeClassifier   9  10   2  15  0.736842\n",
       "              2                     SVC  12   7   6  11  0.733746\n",
       "              3    KNeighborsClassifier  16   3  10   7  0.699690\n",
       "              4      LogisticRegression  12   7   7  10  0.678019\n",
       "              5         DummyClassifier  10   9   7  10  0.577399\n",
       "RFE_30        0  RandomForestClassifier  12   7   5  12  0.786378\n",
       "              1    KNeighborsClassifier  18   1  10   7  0.741486\n",
       "              2  DecisionTreeClassifier   9  10   2  15  0.736842\n",
       "              3                     SVC  13   6   6  11  0.724458\n",
       "              4      LogisticRegression  13   6   7  10  0.702786\n",
       "              5         DummyClassifier  10   9   7  10  0.577399\n",
       "RFE_20        0  RandomForestClassifier  13   6   5  12  0.823529\n",
       "              1                     SVC  12   7   5  12  0.755418\n",
       "              2  DecisionTreeClassifier   9  10   2  15  0.736842\n",
       "              3      LogisticRegression  12   7   4  13  0.708978\n",
       "              4    KNeighborsClassifier  14   5   9   8  0.653251\n",
       "              5         DummyClassifier  10   9   7  10  0.577399"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = pd.concat([ df_featurewiz_val, df_corr_val,  df_rfe30_val, df_rfe20_val],\n",
    "                         keys={ 'Featurewiz_25' : df_featurewiz_val,\n",
    "                                'Corr_41'       : df_corr_val,                                \n",
    "                                'RFE_30'        : df_rfe30_val,\n",
    "                                'RFE_20'        : df_rfe20_val,\n",
    "                               }\n",
    "                       )\n",
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1073e4-c99e-441f-823a-90cd3fd9c0ce",
   "metadata": {},
   "source": [
    "> **Tabela 4.1)** A acima temos os resultados do DataSet de validação para diferences seleções de variaveis explicativas. O melhor modelo foi sempre o **RandomForestClassifier**. A melhor seleção de variaveis explicativas foi o da lib **Featurewiz_25**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c26466-12ac-4bf2-b409-da12f84b59b9",
   "metadata": {},
   "source": [
    "* Resultado no **Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e1e5396-7de7-4332-a7e4-417b6d98d7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>media</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Featurewiz_25</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.817505</td>\n",
       "      <td>0.049075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.801886</td>\n",
       "      <td>0.050124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.799351</td>\n",
       "      <td>0.050576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.769371</td>\n",
       "      <td>0.058287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.691379</td>\n",
       "      <td>0.057426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Corr_41</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.812089</td>\n",
       "      <td>0.049321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.050145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.801420</td>\n",
       "      <td>0.051126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.754148</td>\n",
       "      <td>0.060246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.693509</td>\n",
       "      <td>0.068885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">RFE_30</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.816329</td>\n",
       "      <td>0.050880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.809209</td>\n",
       "      <td>0.049518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.808905</td>\n",
       "      <td>0.048486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.749797</td>\n",
       "      <td>0.062333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.693509</td>\n",
       "      <td>0.068885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">RFE_20</th>\n",
       "      <th>SVC</th>\n",
       "      <td>0.821947</td>\n",
       "      <td>0.048666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.816491</td>\n",
       "      <td>0.048531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.812049</td>\n",
       "      <td>0.043944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.736055</td>\n",
       "      <td>0.064577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.680112</td>\n",
       "      <td>0.058847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         media       std\n",
       "Featurewiz_25 RandomForestClassifier  0.817505  0.049075\n",
       "              LogisticRegression      0.801886  0.050124\n",
       "              SVC                     0.799351  0.050576\n",
       "              KNeighborsClassifier    0.769371  0.058287\n",
       "              DecisionTreeClassifier  0.691379  0.057426\n",
       "Corr_41       RandomForestClassifier  0.812089  0.049321\n",
       "              LogisticRegression      0.801785  0.050145\n",
       "              SVC                     0.801420  0.051126\n",
       "              KNeighborsClassifier    0.754148  0.060246\n",
       "              DecisionTreeClassifier  0.693509  0.068885\n",
       "RFE_30        RandomForestClassifier  0.816329  0.050880\n",
       "              SVC                     0.809209  0.049518\n",
       "              LogisticRegression      0.808905  0.048486\n",
       "              KNeighborsClassifier    0.749797  0.062333\n",
       "              DecisionTreeClassifier  0.693509  0.068885\n",
       "RFE_20        SVC                     0.821947  0.048666\n",
       "              LogisticRegression      0.816491  0.048531\n",
       "              RandomForestClassifier  0.812049  0.043944\n",
       "              KNeighborsClassifier    0.736055  0.064577\n",
       "              DecisionTreeClassifier  0.680112  0.058847"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = pd.concat([ df_featurewiz_cv, df_corr_cv, df_rfe30_cv, df_rfe20_cv],\n",
    "                         keys={ 'Featurewiz_25' : df_featurewiz_cv, \n",
    "                                'Corr_41'     : df_corr_cv,\n",
    "                                'RFE_30'        : df_rfe30_cv,\n",
    "                                'RFE_20'        : df_rfe20_cv\n",
    "                               }\n",
    "                       )\n",
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7bf956-bccb-47c7-9a73-f7a08b50c913",
   "metadata": {},
   "source": [
    "> **Tabela 4.2)** A acima temos os resultados da etapa de Cross Validation para diferences seleções de variaveis explicativas. O melhor modelo foi sempre o **RandomForestClassifier**, exeto na bese RFE_20 onde LogisticRegression foi o melhor, porém nessa base há praticamente um empate entre 3 modelos: **LogisticRegression**, **RandomForestClassifier** e **SVC**. A melhor seleção de variaveis explicativas novamente foi o da lib **featurewiz**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea64f96-6327-47ab-99a1-615d1f6fc451",
   "metadata": {},
   "source": [
    "---\n",
    "# 5) Conclusão\n",
    "\n",
    "Aqui foi reforçado que **RandomForestClassifier** é o melhor modelo. Além disso agora sabemos que a melhor seleção de variaveis explicativa foi a obitida pela lib **featurewiz**. \n",
    "\n",
    "Considerando o **RandomForestClassifier** os melhores hyperparametros para bases foram:\n",
    "\n",
    ">* Base df_featurewiz_25:\n",
    ">   * n_estimators: 400,\n",
    ">   * min_samples_leaf: 4, \n",
    ">   * max_leaf_nodes: 10, \n",
    ">   * max_depth: 7, \n",
    ">   * criterion: 'entropy\n",
    "\n",
    ">* Base df_corr_41:\n",
    ">   * n_estimators: 200,\n",
    ">   * min_samples_leaf: 1, \n",
    ">   * max_leaf_nodes: 9, \n",
    ">   * max_depth: 14, \n",
    ">   * criterion: 'gini\n",
    "\n",
    ">* Base df_RFE_30:\n",
    ">   * n_estimators: 250,\n",
    ">   * min_samples_leaf: 2, \n",
    ">   * max_leaf_nodes: 10, \n",
    ">   * max_depth: 18, \n",
    ">   * criterion: 'gini\n",
    "\n",
    ">* Base df_RFE_20:\n",
    ">   * n_estimators: 250,\n",
    ">   * min_samples_leaf: 2, \n",
    ">   * max_leaf_nodes: 10, \n",
    ">   * max_depth: 18, \n",
    ">   * criterion: 'gini\n",
    "\n",
    "Assim a melhor opção é usar **RandomForestClassifier** com a **df_featurewiz_25**. No próximo [notebook](https://github.com/HenriqueCCdA/BC_DS_Projeto_Final/blob/main/Notebooks/ML/Treinamento_modelo_final.ipynb) irá treinar o **RandomForestClassifier** utilizando toda a base de dados para obter o modelo final de **ML**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331d860d-68f2-450b-9e58-7a6d6c251eca",
   "metadata": {},
   "source": [
    "---\n",
    "Navegação:\n",
    "\n",
    "---\n",
    "\n",
    "[Voltar para o Notebook anterior(Primeiro Treinamento)](https://github.com/HenriqueCCdA/BC_DS_Projeto_Final/blob/main/Notebooks/ML/treinamentos_dados1.ipynb)\n",
    "\n",
    "[Ir para o proximo notebook(Treinamento do modelo final)](https://github.com/HenriqueCCdA/BC_DS_Projeto_Final/blob/main/Notebooks/ML/Treinamento_modelo_final.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "[Retornar para README principal](https://github.com/HenriqueCCdA/BC_DS_Projeto_Final)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
